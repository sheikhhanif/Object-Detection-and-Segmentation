{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngYvg6JLDUgP"
   },
   "source": [
    "##  Applying knowledge to other fields: Transfer learning\n",
    "Transfer learning is a very convenient technique consisting in using a previously trained model, reusing the weights adjusted for a benchmark (in the case of image classification problems it is Imagenet), \n",
    "In this section we will gather images from two different flower types, coming from the flower17 dataset. \n",
    "It is a 17 category flower dataset with 80 images for each class. The flowers chosen are some common flowers in the UK. The images have large scale, pose and light variations and there are also classes with large varations of images within the class and close similarity to other classes.\n",
    "In this case we will gather the first 2 classes (Daffodil and Coltsfoot), and build a classifier on top of the pretrained VGG16 network.\n",
    "\n",
    "Previously, we will will do image data aughmentation, because the images quantity could be not enough to abstract all the elements of any species.\n",
    "Let's start by importing all the needed libraries, including applications, preprocession, the checkpoint model and associated object, to allow saving the intermediate steps, and the cv2 and Numpy ones, for image processing and numerical base operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2865,
     "status": "ok",
     "timestamp": 1524741632355,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "4YAsHjAYDUgW",
    "outputId": "7913bd35-017c-4238-d4e0-e0d2f43b2ad0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions,preprocess_input\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import urllib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLc87yXYDUg1"
   },
   "source": [
    "In this section we will define all the variables affectin the input, data sources, and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_60pIoLuDUg3"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "train_data_dir = \"train\"\n",
    "validation_data_dir = \"validation\"\n",
    "nb_train_samples = 300\n",
    "nb_validation_samples = 100 \n",
    "batch_size = 16\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7u8uKThDUhD"
   },
   "source": [
    "Now we will invoke the VGG16 pretrained model, not including the top flattening layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3079,
     "status": "ok",
     "timestamp": 1524741636906,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "Fh1i6tccDUhG",
    "outputId": "472a34c2-d9e9-47fe-85b8-53247d74c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJ6E9Vn7DUhU"
   },
   "source": [
    "Now its time to compile the model, and create the  image data authmentation object for the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2952,
     "status": "ok",
     "timestamp": 1524741640101,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "YdKffqFxPqEM",
    "outputId": "fa929c2c-32b1-4526-c617-a3377fa13692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-04-26 10:23:43--  https://s3.amazonaws.com/italia18/transfer_learning_dataset.zip\r\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.33.186\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.33.186|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7848999 (7.5M) [application/zip]\n",
      "Saving to: ‘transfer_learning_dataset.zip’\n",
      "\n",
      "transfer_learning_d 100%[===================>]   7.49M  5.89MB/s    in 1.3s    \n",
      "\n",
      "2018-04-26 10:23:45 (5.89 MB/s) - ‘transfer_learning_dataset.zip’ saved [7848999/7848999]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/italia18/transfer_learning_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1573,
     "status": "ok",
     "timestamp": 1524741712726,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "pUEOhp8YxSw_",
    "outputId": "d77ad6bc-f01d-4abd-86ae-c34ddfa413fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  transfer_learning_dataset.zip\r\n",
      "   creating: test/\r\n",
      "  inflating: test/butt2.jpg          \r\n",
      "  inflating: test/butter1.jpg        \r\n",
      "  inflating: test/coldsfoot.jpg      \r\n",
      "  inflating: test/coltsfoot-flower.jpg  \r\n",
      "  inflating: test/daff1.jpg          \r\n",
      "  inflating: test/gaff2.jpg          \r\n",
      "  inflating: test/galan.jpg          \r\n",
      "  inflating: test/galant2.jpg        \r\n",
      "   creating: train/\r\n",
      "   creating: train/1/\r\n",
      "  inflating: train/1/image_0001.jpg  \r\n",
      "  inflating: train/1/image_0002.jpg  \r\n",
      "  inflating: train/1/image_0003.jpg  \r\n",
      "  inflating: train/1/image_0004.jpg  \r\n",
      "  inflating: train/1/image_0005.jpg  \r\n",
      "  inflating: train/1/image_0006.jpg  \r\n",
      "  inflating: train/1/image_0007.jpg  \r\n",
      "  inflating: train/1/image_0008.jpg  \r\n",
      "  inflating: train/1/image_0009.jpg  \r\n",
      "  inflating: train/1/image_0010.jpg  \r\n",
      "  inflating: train/1/image_0011.jpg  \r\n",
      "  inflating: train/1/image_0012.jpg  \r\n",
      "  inflating: train/1/image_0013.jpg  \r\n",
      "  inflating: train/1/image_0014.jpg  \r\n",
      "  inflating: train/1/image_0015.jpg  \r\n",
      "  inflating: train/1/image_0016.jpg  \r\n",
      "  inflating: train/1/image_0017.jpg  \r\n",
      "  inflating: train/1/image_0018.jpg  \r\n",
      "  inflating: train/1/image_0019.jpg  \r\n",
      "  inflating: train/1/image_0020.jpg  \r\n",
      "  inflating: train/1/image_0021.jpg  \r\n",
      "  inflating: train/1/image_0022.jpg  \r\n",
      "  inflating: train/1/image_0023.jpg  \r\n",
      "  inflating: train/1/image_0024.jpg  \r\n",
      "  inflating: train/1/image_0025.jpg  \r\n",
      "  inflating: train/1/image_0026.jpg  \r\n",
      "  inflating: train/1/image_0027.jpg  \r\n",
      "  inflating: train/1/image_0028.jpg  \r\n",
      "  inflating: train/1/image_0029.jpg  \r\n",
      "  inflating: train/1/image_0030.jpg  \r\n",
      "  inflating: train/1/image_0031.jpg  \r\n",
      "  inflating: train/1/image_0032.jpg  \r\n",
      "  inflating: train/1/image_0033.jpg  \r\n",
      "  inflating: train/1/image_0034.jpg  \r\n",
      "  inflating: train/1/image_0035.jpg  \r\n",
      "  inflating: train/1/image_0036.jpg  \r\n",
      "  inflating: train/1/image_0037.jpg  \r\n",
      "  inflating: train/1/image_0038.jpg  \r\n",
      "  inflating: train/1/image_0039.jpg  \r\n",
      "  inflating: train/1/image_0040.jpg  \r\n",
      "  inflating: train/1/image_0041.jpg  \r\n",
      "  inflating: train/1/image_0042.jpg  \r\n",
      "  inflating: train/1/image_0043.jpg  \r\n",
      "  inflating: train/1/image_0044.jpg  \r\n",
      "  inflating: train/1/image_0045.jpg  \r\n",
      "  inflating: train/1/image_0046.jpg  \r\n",
      "  inflating: train/1/image_0047.jpg  \r\n",
      "  inflating: train/1/image_0048.jpg  \r\n",
      "  inflating: train/1/image_0049.jpg  \r\n",
      "  inflating: train/1/image_0050.jpg  \r\n",
      "  inflating: train/1/image_0051.jpg  \r\n",
      "  inflating: train/1/image_0052.jpg  \r\n",
      "  inflating: train/1/image_0053.jpg  \r\n",
      "  inflating: train/1/image_0054.jpg  \r\n",
      "  inflating: train/1/image_0055.jpg  \r\n",
      "  inflating: train/1/image_0056.jpg  \r\n",
      "  inflating: train/1/image_0057.jpg  \r\n",
      "  inflating: train/1/image_0058.jpg  \r\n",
      "  inflating: train/1/image_0059.jpg  \r\n",
      "  inflating: train/1/image_0060.jpg  \r\n",
      "   creating: train/2/\r\n",
      "  inflating: train/2/image_0081.jpg  \r\n",
      "  inflating: train/2/image_0082.jpg  \r\n",
      "  inflating: train/2/image_0083.jpg  \r\n",
      "  inflating: train/2/image_0084.jpg  \r\n",
      "  inflating: train/2/image_0085.jpg  \r\n",
      "  inflating: train/2/image_0086.jpg  \n",
      "  inflating: train/2/image_0087.jpg  \n",
      "  inflating: train/2/image_0088.jpg  \n",
      "  inflating: train/2/image_0089.jpg  \n",
      "  inflating: train/2/image_0090.jpg  \n",
      "  inflating: train/2/image_0091.jpg  \n",
      "  inflating: train/2/image_0092.jpg  \n",
      "  inflating: train/2/image_0093.jpg  \n",
      "  inflating: train/2/image_0094.jpg  \n",
      "  inflating: train/2/image_0095.jpg  \n",
      "  inflating: train/2/image_0096.jpg  \n",
      "  inflating: train/2/image_0097.jpg  \n",
      "  inflating: train/2/image_0098.jpg  \n",
      "  inflating: train/2/image_0099.jpg  \n",
      "  inflating: train/2/image_0100.jpg  \n",
      "  inflating: train/2/image_0101.jpg  \n",
      "  inflating: train/2/image_0102.jpg  \n",
      "  inflating: train/2/image_0103.jpg  \n",
      "  inflating: train/2/image_0104.jpg  \n",
      "  inflating: train/2/image_0105.jpg  \n",
      "  inflating: train/2/image_0106.jpg  \n",
      "  inflating: train/2/image_0107.jpg  \n",
      "  inflating: train/2/image_0108.jpg  \n",
      "  inflating: train/2/image_0109.jpg  \n",
      "  inflating: train/2/image_0110.jpg  \n",
      "  inflating: train/2/image_0111.jpg  \n",
      "  inflating: train/2/image_0112.jpg  \n",
      "  inflating: train/2/image_0113.jpg  \n",
      "  inflating: train/2/image_0114.jpg  \n",
      "  inflating: train/2/image_0115.jpg  \n",
      "  inflating: train/2/image_0116.jpg  \n",
      "  inflating: train/2/image_0117.jpg  \n",
      "  inflating: train/2/image_0118.jpg  \n",
      "  inflating: train/2/image_0119.jpg  \n",
      "  inflating: train/2/image_0120.jpg  \n",
      "  inflating: train/2/image_0121.jpg  \n",
      "  inflating: train/2/image_0122.jpg  \n",
      "  inflating: train/2/image_0123.jpg  \n",
      "  inflating: train/2/image_0124.jpg  \n",
      "  inflating: train/2/image_0125.jpg  \n",
      "  inflating: train/2/image_0126.jpg  \n",
      "  inflating: train/2/image_0127.jpg  \n",
      "  inflating: train/2/image_0128.jpg  \n",
      "  inflating: train/2/image_0129.jpg  \n",
      "  inflating: train/2/image_0130.jpg  \n",
      "  inflating: train/2/image_0131.jpg  \n",
      "  inflating: train/2/image_0132.jpg  \n",
      "  inflating: train/2/image_0133.jpg  \n",
      "  inflating: train/2/image_0134.jpg  \n",
      "  inflating: train/2/image_0135.jpg  \n",
      "  inflating: train/2/image_0136.jpg  \n",
      "  inflating: train/2/image_0137.jpg  \n",
      "  inflating: train/2/image_0138.jpg  \n",
      "  inflating: train/2/image_0139.jpg  \n",
      "  inflating: train/2/image_0140.jpg  \n",
      "   creating: validation/\n",
      "   creating: validation/1/\n",
      "  inflating: validation/1/image_0061.jpg  \n",
      "  inflating: validation/1/image_0062.jpg  \n",
      "  inflating: validation/1/image_0063.jpg  \n",
      "  inflating: validation/1/image_0064.jpg  \n",
      "  inflating: validation/1/image_0065.jpg  \n",
      "  inflating: validation/1/image_0066.jpg  \n",
      "  inflating: validation/1/image_0067.jpg  \n",
      "  inflating: validation/1/image_0068.jpg  \n",
      "  inflating: validation/1/image_0069.jpg  \n",
      "  inflating: validation/1/image_0070.jpg  \n",
      "  inflating: validation/1/image_0071.jpg  \n",
      "  inflating: validation/1/image_0072.jpg  \n",
      "  inflating: validation/1/image_0073.jpg  \n",
      "  inflating: validation/1/image_0074.jpg  \n",
      "  inflating: validation/1/image_0075.jpg  \n",
      "  inflating: validation/1/image_0076.jpg  \n",
      "  inflating: validation/1/image_0077.jpg  \n",
      "  inflating: validation/1/image_0078.jpg  \n",
      "  inflating: validation/1/image_0079.jpg  \n",
      "  inflating: validation/1/image_0080.jpg  \n",
      "   creating: validation/2/\n",
      "  inflating: validation/2/image_0141.jpg  \n",
      "  inflating: validation/2/image_0142.jpg  \n",
      "  inflating: validation/2/image_0143.jpg  \n",
      "  inflating: validation/2/image_0144.jpg  \n",
      "  inflating: validation/2/image_0145.jpg  \n",
      "  inflating: validation/2/image_0146.jpg  \n",
      "  inflating: validation/2/image_0147.jpg  \n",
      "  inflating: validation/2/image_0148.jpg  \n",
      "  inflating: validation/2/image_0149.jpg  \n",
      "  inflating: validation/2/image_0150.jpg  \n",
      "  inflating: validation/2/image_0151.jpg  \n",
      "  inflating: validation/2/image_0152.jpg  \n",
      "  inflating: validation/2/image_0153.jpg  \n",
      "  inflating: validation/2/image_0154.jpg  \n",
      "  inflating: validation/2/image_0155.jpg  \n",
      "  inflating: validation/2/image_0156.jpg  \n",
      "  inflating: validation/2/image_0157.jpg  \n",
      "  inflating: validation/2/image_0158.jpg  \n",
      "  inflating: validation/2/image_0159.jpg  \n",
      "  inflating: validation/2/image_0160.jpg  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o transfer_learning_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qCMx0B4rDUhY"
   },
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oCchbC8DUhg"
   },
   "source": [
    "Now we will properly generate the new augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3090
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2240,
     "status": "ok",
     "timestamp": 1524741734358,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "JE9iXT9bEHUs",
    "outputId": "0547ed70-2bbd-4a16-8315-46480f62ceac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  transfer_learning_dataset.zip\r\n",
      "  inflating: test/butt2.jpg          \r\n",
      "  inflating: test/butter1.jpg        \r\n",
      "  inflating: test/coldsfoot.jpg      \r\n",
      "  inflating: test/coltsfoot-flower.jpg  \r\n",
      "  inflating: test/daff1.jpg          \r\n",
      "  inflating: test/gaff2.jpg          \r\n",
      "  inflating: test/galan.jpg          \r\n",
      "  inflating: test/galant2.jpg        \r\n",
      "  inflating: train/1/image_0001.jpg  \r\n",
      "  inflating: train/1/image_0002.jpg  \r\n",
      "  inflating: train/1/image_0003.jpg  \r\n",
      "  inflating: train/1/image_0004.jpg  \r\n",
      "  inflating: train/1/image_0005.jpg  \r\n",
      "  inflating: train/1/image_0006.jpg  \r\n",
      "  inflating: train/1/image_0007.jpg  \r\n",
      "  inflating: train/1/image_0008.jpg  \r\n",
      "  inflating: train/1/image_0009.jpg  \r\n",
      "  inflating: train/1/image_0010.jpg  \r\n",
      "  inflating: train/1/image_0011.jpg  \r\n",
      "  inflating: train/1/image_0012.jpg  \r\n",
      "  inflating: train/1/image_0013.jpg  \r\n",
      "  inflating: train/1/image_0014.jpg  \r\n",
      "  inflating: train/1/image_0015.jpg  \r\n",
      "  inflating: train/1/image_0016.jpg  \r\n",
      "  inflating: train/1/image_0017.jpg  \r\n",
      "  inflating: train/1/image_0018.jpg  \r\n",
      "  inflating: train/1/image_0019.jpg  \r\n",
      "  inflating: train/1/image_0020.jpg  \r\n",
      "  inflating: train/1/image_0021.jpg  \r\n",
      "  inflating: train/1/image_0022.jpg  \r\n",
      "  inflating: train/1/image_0023.jpg  \r\n",
      "  inflating: train/1/image_0024.jpg  \r\n",
      "  inflating: train/1/image_0025.jpg  \r\n",
      "  inflating: train/1/image_0026.jpg  \r\n",
      "  inflating: train/1/image_0027.jpg  \r\n",
      "  inflating: train/1/image_0028.jpg  \r\n",
      "  inflating: train/1/image_0029.jpg  \r\n",
      "  inflating: train/1/image_0030.jpg  \r\n",
      "  inflating: train/1/image_0031.jpg  \r\n",
      "  inflating: train/1/image_0032.jpg  \r\n",
      "  inflating: train/1/image_0033.jpg  \r\n",
      "  inflating: train/1/image_0034.jpg  \r\n",
      "  inflating: train/1/image_0035.jpg  \r\n",
      "  inflating: train/1/image_0036.jpg  \r\n",
      "  inflating: train/1/image_0037.jpg  \r\n",
      "  inflating: train/1/image_0038.jpg  \r\n",
      "  inflating: train/1/image_0039.jpg  \r\n",
      "  inflating: train/1/image_0040.jpg  \r\n",
      "  inflating: train/1/image_0041.jpg  \r\n",
      "  inflating: train/1/image_0042.jpg  \r\n",
      "  inflating: train/1/image_0043.jpg  \r\n",
      "  inflating: train/1/image_0044.jpg  \r\n",
      "  inflating: train/1/image_0045.jpg  \r\n",
      "  inflating: train/1/image_0046.jpg  \r\n",
      "  inflating: train/1/image_0047.jpg  \r\n",
      "  inflating: train/1/image_0048.jpg  \r\n",
      "  inflating: train/1/image_0049.jpg  \r\n",
      "  inflating: train/1/image_0050.jpg  \r\n",
      "  inflating: train/1/image_0051.jpg  \r\n",
      "  inflating: train/1/image_0052.jpg  \r\n",
      "  inflating: train/1/image_0053.jpg  \r\n",
      "  inflating: train/1/image_0054.jpg  \r\n",
      "  inflating: train/1/image_0055.jpg  \r\n",
      "  inflating: train/1/image_0056.jpg  \r\n",
      "  inflating: train/1/image_0057.jpg  \r\n",
      "  inflating: train/1/image_0058.jpg  \r\n",
      "  inflating: train/1/image_0059.jpg  \r\n",
      "  inflating: train/1/image_0060.jpg  \r\n",
      "  inflating: train/2/image_0081.jpg  \r\n",
      "  inflating: train/2/image_0082.jpg  \r\n",
      "  inflating: train/2/image_0083.jpg  \r\n",
      "  inflating: train/2/image_0084.jpg  \r\n",
      "  inflating: train/2/image_0085.jpg  \r\n",
      "  inflating: train/2/image_0086.jpg  \r\n",
      "  inflating: train/2/image_0087.jpg  \r\n",
      "  inflating: train/2/image_0088.jpg  \n",
      "  inflating: train/2/image_0089.jpg  \n",
      "  inflating: train/2/image_0090.jpg  \n",
      "  inflating: train/2/image_0091.jpg  \n",
      "  inflating: train/2/image_0092.jpg  \n",
      "  inflating: train/2/image_0093.jpg  \n",
      "  inflating: train/2/image_0094.jpg  \n",
      "  inflating: train/2/image_0095.jpg  \n",
      "  inflating: train/2/image_0096.jpg  \n",
      "  inflating: train/2/image_0097.jpg  \n",
      "  inflating: train/2/image_0098.jpg  \n",
      "  inflating: train/2/image_0099.jpg  \n",
      "  inflating: train/2/image_0100.jpg  \n",
      "  inflating: train/2/image_0101.jpg  \n",
      "  inflating: train/2/image_0102.jpg  \n",
      "  inflating: train/2/image_0103.jpg  \n",
      "  inflating: train/2/image_0104.jpg  \n",
      "  inflating: train/2/image_0105.jpg  \n",
      "  inflating: train/2/image_0106.jpg  \n",
      "  inflating: train/2/image_0107.jpg  \n",
      "  inflating: train/2/image_0108.jpg  \n",
      "  inflating: train/2/image_0109.jpg  \n",
      "  inflating: train/2/image_0110.jpg  \n",
      "  inflating: train/2/image_0111.jpg  \n",
      "  inflating: train/2/image_0112.jpg  \n",
      "  inflating: train/2/image_0113.jpg  \n",
      "  inflating: train/2/image_0114.jpg  \n",
      "  inflating: train/2/image_0115.jpg  \n",
      "  inflating: train/2/image_0116.jpg  \n",
      "  inflating: train/2/image_0117.jpg  \n",
      "  inflating: train/2/image_0118.jpg  \n",
      "  inflating: train/2/image_0119.jpg  \n",
      "  inflating: train/2/image_0120.jpg  \n",
      "  inflating: train/2/image_0121.jpg  \n",
      "  inflating: train/2/image_0122.jpg  \n",
      "  inflating: train/2/image_0123.jpg  \n",
      "  inflating: train/2/image_0124.jpg  \n",
      "  inflating: train/2/image_0125.jpg  \n",
      "  inflating: train/2/image_0126.jpg  \n",
      "  inflating: train/2/image_0127.jpg  \n",
      "  inflating: train/2/image_0128.jpg  \n",
      "  inflating: train/2/image_0129.jpg  \n",
      "  inflating: train/2/image_0130.jpg  \n",
      "  inflating: train/2/image_0131.jpg  \n",
      "  inflating: train/2/image_0132.jpg  \n",
      "  inflating: train/2/image_0133.jpg  \n",
      "  inflating: train/2/image_0134.jpg  \n",
      "  inflating: train/2/image_0135.jpg  \n",
      "  inflating: train/2/image_0136.jpg  \n",
      "  inflating: train/2/image_0137.jpg  \n",
      "  inflating: train/2/image_0138.jpg  \n",
      "  inflating: train/2/image_0139.jpg  \n",
      "  inflating: train/2/image_0140.jpg  \n",
      "  inflating: validation/1/image_0061.jpg  \n",
      "  inflating: validation/1/image_0062.jpg  \n",
      "  inflating: validation/1/image_0063.jpg  \n",
      "  inflating: validation/1/image_0064.jpg  \n",
      "  inflating: validation/1/image_0065.jpg  \n",
      "  inflating: validation/1/image_0066.jpg  \n",
      "  inflating: validation/1/image_0067.jpg  \n",
      "  inflating: validation/1/image_0068.jpg  \n",
      "  inflating: validation/1/image_0069.jpg  \n",
      "  inflating: validation/1/image_0070.jpg  \n",
      "  inflating: validation/1/image_0071.jpg  \n",
      "  inflating: validation/1/image_0072.jpg  \n",
      "  inflating: validation/1/image_0073.jpg  \n",
      "  inflating: validation/1/image_0074.jpg  \n",
      "  inflating: validation/1/image_0075.jpg  \n",
      "  inflating: validation/1/image_0076.jpg  \n",
      "  inflating: validation/1/image_0077.jpg  \n",
      "  inflating: validation/1/image_0078.jpg  \n",
      "  inflating: validation/1/image_0079.jpg  \n",
      "  inflating: validation/1/image_0080.jpg  \n",
      "  inflating: validation/2/image_0141.jpg  \n",
      "  inflating: validation/2/image_0142.jpg  \n",
      "  inflating: validation/2/image_0143.jpg  \n",
      "  inflating: validation/2/image_0144.jpg  \n",
      "  inflating: validation/2/image_0145.jpg  \n",
      "  inflating: validation/2/image_0146.jpg  \n",
      "  inflating: validation/2/image_0147.jpg  \n",
      "  inflating: validation/2/image_0148.jpg  \n",
      "  inflating: validation/2/image_0149.jpg  \n",
      "  inflating: validation/2/image_0150.jpg  \n",
      "  inflating: validation/2/image_0151.jpg  \n",
      "  inflating: validation/2/image_0152.jpg  \n",
      "  inflating: validation/2/image_0153.jpg  \n",
      "  inflating: validation/2/image_0154.jpg  \n",
      "  inflating: validation/2/image_0155.jpg  \n",
      "  inflating: validation/2/image_0156.jpg  \n",
      "  inflating: validation/2/image_0157.jpg  \n",
      "  inflating: validation/2/image_0158.jpg  \n",
      "  inflating: validation/2/image_0159.jpg  \n",
      "  inflating: validation/2/image_0160.jpg  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o transfer_learning_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1524741767782,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "QWP-sqbJDUhk",
    "outputId": "5ccd0b17-0e74-480a-a8be-79a115f5e6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAzuW65ODUht"
   },
   "source": [
    "It's time to fit the new final layers for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "0SxfYqe3DUhv",
    "outputId": "30441abd-952c-4e22-d580-b37fdf673305"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., callbacks=[<keras.ca..., steps_per_epoch=18, epochs=20, validation_steps=100)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/18 [==>...........................] - ETA: 6:56 - loss: 0.7705 - acc: 0.4375"
     ]
    }
   ],
   "source": [
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "nb_epoch = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZWGYOoLDUh5"
   },
   "source": [
    "Then let's try with a daffoil image, testing the output of the classifier, which should output an array close to the [1.,0.] value, indicating that the probability for the first option is very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Y4QrOntYvpwW"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "im = cv2.resize(cv2.imread('test/gaff2.jpg'), (img_width, img_height))\n",
    "im = np.expand_dims(im, axis=0).astype(np.float32)\n",
    "im=preprocess_input(im)\n",
    "print (im.shape)\n",
    "out = model_final.predict(im)\n",
    "model_classes=[\"Daffodil\",\"Coltsfoot\"]\n",
    "print (model_classes[np.argmax(out)])\n",
    "print (out)\n",
    "print (\"Probability: \", out[0][np.argmax(out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lxQuQ8lnDUh7"
   },
   "outputs": [],
   "source": [
    "def show_result(im):\n",
    "  im = cv2.resize(im, (img_width, img_height))\n",
    "  im = np.expand_dims(im, axis=0).astype(np.float32)\n",
    "  im=preprocess_input(im)\n",
    "  out = model_final.predict(im)\n",
    "  model_classes=[\"Daffodil\",\"Coltsfoot\"]\n",
    "  print (model_classes[np.argmax(out)])\n",
    "  print (out)\n",
    "  print (\"Probability: \", out[0][np.argmax(out)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 953,
     "status": "ok",
     "timestamp": 1524222749849,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "4QY1EqrGoU3E",
    "outputId": "f7a2162e-5298-4598-8c3b-60a9f87ab10e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model on image https://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Coltsfoot.jpg/800px-Coltsfoot.jpg...\n",
      "(1, 224, 224, 3)\n",
      "Coltsfoot\n",
      "[[0. 1.]]\n",
      "Probability:  1.0\n"
     ]
    }
   ],
   "source": [
    "#@Test your images\n",
    "#@title Run on sample images {display-mode: \"form\"}\n",
    "\n",
    "SAMPLE_IMAGE = 'image1'  # @param ['image1', 'image2', 'image3']\n",
    "IMAGE_URL = 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Coltsfoot.jpg/800px-Coltsfoot.jpg'  #@param {type:\"string\"}\n",
    "\n",
    "_SAMPLE_URL = ('https://github.com/tensorflow/models/blob/master/research/'\n",
    "               'deeplab/g3doc/img/%s.jpg?raw=true')\n",
    "\n",
    "\n",
    "def run_visualization(url):\n",
    "  \"\"\"Running model on\"\"\"\n",
    "  try:\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    orignal_im = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "  except IOError:\n",
    "    print('Cannot retrieve image. Please check url: ' + url)\n",
    "    return\n",
    "\n",
    "  print('running model on image %s...' % url)\n",
    "\n",
    "\n",
    "  show_result(orignal_im)\n",
    "\n",
    "\n",
    "image_url = IMAGE_URL or _SAMPLE_URL % SAMPLE_IMAGE\n",
    "run_visualization(image_url)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "3_Transfer Learning For classification.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
