{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RcVl-HhjFN2F"
   },
   "source": [
    "# Download the project and get our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14111,
     "status": "ok",
     "timestamp": 1524748994827,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "ayao7u4XTJhy",
    "outputId": "694d137e-e7b5-4a3a-d593-cbb16b10c03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mask_RCNN'...\n",
      "remote: Counting objects: 653, done.\u001b[K\n",
      "remote: Total 653 (delta 0), reused 0 (delta 0), pack-reused 653\u001b[K\n",
      "Receiving objects: 100% (653/653), 100.12 MiB | 39.88 MiB/s, done.\n",
      "Resolving deltas: 100% (367/367), done.\n",
      "--2018-04-26 12:26:18--  https://s3.amazonaws.com/italia18/dataset_segmentation.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.82.19\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.82.19|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14600869 (14M) [application/zip]\n",
      "Saving to: ‘dataset_segmentation.zip’\n",
      "\n",
      "dataset_segmentatio 100%[===================>]  13.92M  29.2MB/s    in 0.5s    \n",
      "\n",
      "2018-04-26 12:26:18 (29.2 MB/s) - ‘dataset_segmentation.zip’ saved [14600869/14600869]\n",
      "\n",
      "Archive:  dataset_segmentation.zip\n",
      "   creating: dataset_segmentation/\n",
      "  inflating: dataset_segmentation/demo.ipynb  \n",
      "  inflating: dataset_segmentation/segmentation.py  \n",
      "   creating: dataset_segmentation/train/\n",
      "  inflating: dataset_segmentation/train/01.jpg  \n",
      "  inflating: dataset_segmentation/train/02.jpg  \n",
      "  inflating: dataset_segmentation/train/03.jpg  \n",
      "  inflating: dataset_segmentation/train/04.jpg  \n",
      "  inflating: dataset_segmentation/train/05.jpg  \n",
      "  inflating: dataset_segmentation/train/06.jpg  \n",
      "  inflating: dataset_segmentation/train/07.jpg  \n",
      "  inflating: dataset_segmentation/train/08.jpg  \n",
      "  inflating: dataset_segmentation/train/09.jpg  \n",
      "  inflating: dataset_segmentation/train/10.jpg  \n",
      "  inflating: dataset_segmentation/train/11.jpg  \n",
      "  inflating: dataset_segmentation/train/12.jpg  \n",
      "  inflating: dataset_segmentation/train/13.jpg  \n",
      "  inflating: dataset_segmentation/train/14.jpg  \n",
      "  inflating: dataset_segmentation/train/15.jpg  \n",
      "  inflating: dataset_segmentation/train/16.jpg  \n",
      "  inflating: dataset_segmentation/train/17.jpg  \n",
      "  inflating: dataset_segmentation/train/18.jpg  \n",
      "  inflating: dataset_segmentation/train/19.jpg  \n",
      "  inflating: dataset_segmentation/train/20.jpg  \n",
      "  inflating: dataset_segmentation/train/21.jpg  \n",
      "  inflating: dataset_segmentation/train/22.jpg  \n",
      "  inflating: dataset_segmentation/train/via_region_data.json  \n",
      "   creating: dataset_segmentation/val/\n",
      "  inflating: dataset_segmentation/val/23.jpg  \n",
      "  inflating: dataset_segmentation/val/25.jpg  \n",
      "  inflating: dataset_segmentation/val/26.jpg  \n",
      "  inflating: dataset_segmentation/val/via_region_data (3).json  \n",
      "  inflating: dataset_segmentation/val/via_region_data.json  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!git clone https://github.com/matterport/Mask_RCNN.git\n",
    "os.chdir('Mask_RCNN')\n",
    "os.chdir('samples')\n",
    "!wget https://s3.amazonaws.com/italia18/dataset_segmentation.zip\n",
    "!unzip dataset_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPSo4vWlPcOL"
   },
   "source": [
    "# Train the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 5500
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4933915,
     "status": "ok",
     "timestamp": 1524753928925,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "plmwF7h1TvVd",
    "outputId": "f76d1aa4-13a1-42f6-abb9-99905e5d30a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  coco\n",
      "Dataset:  ./\n",
      "Logs:  /content/Mask_RCNN/logs\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           segmentation\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Downloading pretrained model to /content/Mask_RCNN/mask_rcnn_coco.h5 ...\n",
      "... done downloading pretrained model!\n",
      "Loading weights  /content/Mask_RCNN/mask_rcnn_coco.h5\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /content/Mask_RCNN/logs/segmentation20180426T1226/mask_rcnn_segmentation_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 1.1953 - rpn_class_loss: 0.0243 - rpn_bbox_loss: 0.3300 - mrcnn_class_loss: 0.1219 - mrcnn_bbox_loss: 0.2875 - mrcnn_mask_loss: 0.4315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2348: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 396s 4s/step - loss: 1.1887 - rpn_class_loss: 0.0241 - rpn_bbox_loss: 0.3284 - mrcnn_class_loss: 0.1212 - mrcnn_bbox_loss: 0.2860 - mrcnn_mask_loss: 0.4290 - val_loss: 0.6333 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.1369 - val_mrcnn_class_loss: 0.0351 - val_mrcnn_bbox_loss: 0.2946 - val_mrcnn_mask_loss: 0.1570\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 352s 4s/step - loss: 0.2816 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.0548 - mrcnn_class_loss: 0.0268 - mrcnn_bbox_loss: 0.0734 - mrcnn_mask_loss: 0.1195 - val_loss: 0.4239 - val_rpn_class_loss: 0.0059 - val_rpn_bbox_loss: 0.1003 - val_mrcnn_class_loss: 0.0458 - val_mrcnn_bbox_loss: 0.1441 - val_mrcnn_mask_loss: 0.1279\n",
      "Epoch 3/30\n",
      " 18/100 [====>.........................] - ETA: 3:35 - loss: 0.2063 - rpn_class_loss: 0.0048 - rpn_bbox_loss: 0.0398 - mrcnn_class_loss: 0.0259 - mrcnn_bbox_loss: 0.0393 - mrcnn_mask_loss: 0.0965100/100 [==============================] - 351s 4s/step - loss: 0.1766 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0284 - mrcnn_class_loss: 0.0208 - mrcnn_bbox_loss: 0.0309 - mrcnn_mask_loss: 0.0927 - val_loss: 0.4393 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.1319 - val_mrcnn_class_loss: 0.0432 - val_mrcnn_bbox_loss: 0.1238 - val_mrcnn_mask_loss: 0.1362\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 350s 3s/step - loss: 0.1389 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0179 - mrcnn_class_loss: 0.0174 - mrcnn_bbox_loss: 0.0240 - mrcnn_mask_loss: 0.0767 - val_loss: 0.4155 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.1210 - val_mrcnn_class_loss: 0.0416 - val_mrcnn_bbox_loss: 0.1265 - val_mrcnn_mask_loss: 0.1227\n",
      "Epoch 5/30\n",
      " 26/100 [======>.......................] - ETA: 3:13 - loss: 0.1188 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0126 - mrcnn_class_loss: 0.0176 - mrcnn_bbox_loss: 0.0191 - mrcnn_mask_loss: 0.0670100/100 [==============================] - 350s 3s/step - loss: 0.1146 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0128 - mrcnn_class_loss: 0.0182 - mrcnn_bbox_loss: 0.0183 - mrcnn_mask_loss: 0.0631 - val_loss: 0.4017 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.1345 - val_mrcnn_class_loss: 0.0487 - val_mrcnn_bbox_loss: 0.0972 - val_mrcnn_mask_loss: 0.1172\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 350s 4s/step - loss: 0.0975 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0074 - mrcnn_class_loss: 0.0152 - mrcnn_bbox_loss: 0.0147 - mrcnn_mask_loss: 0.0587 - val_loss: 0.3823 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.1136 - val_mrcnn_class_loss: 0.0404 - val_mrcnn_bbox_loss: 0.1064 - val_mrcnn_mask_loss: 0.1191\n",
      "Epoch 7/30\n",
      " 28/100 [=======>......................] - ETA: 3:08 - loss: 0.0896 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0071 - mrcnn_class_loss: 0.0158 - mrcnn_bbox_loss: 0.0134 - mrcnn_mask_loss: 0.0522100/100 [==============================] - 350s 3s/step - loss: 0.0927 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0081 - mrcnn_class_loss: 0.0150 - mrcnn_bbox_loss: 0.0158 - mrcnn_mask_loss: 0.0524 - val_loss: 0.4223 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1104 - val_mrcnn_class_loss: 0.0385 - val_mrcnn_bbox_loss: 0.1448 - val_mrcnn_mask_loss: 0.1260\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 349s 3s/step - loss: 0.0824 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0055 - mrcnn_class_loss: 0.0128 - mrcnn_bbox_loss: 0.0152 - mrcnn_mask_loss: 0.0476 - val_loss: 0.4028 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1004 - val_mrcnn_class_loss: 0.0604 - val_mrcnn_bbox_loss: 0.1097 - val_mrcnn_mask_loss: 0.1296\n",
      "Epoch 9/30\n",
      " 28/100 [=======>......................] - ETA: 3:08 - loss: 0.0735 - rpn_class_loss: 9.6192e-04 - rpn_bbox_loss: 0.0057 - mrcnn_class_loss: 0.0139 - mrcnn_bbox_loss: 0.0074 - mrcnn_mask_loss: 0.0455100/100 [==============================] - 350s 4s/step - loss: 0.0696 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0043 - mrcnn_class_loss: 0.0129 - mrcnn_bbox_loss: 0.0070 - mrcnn_mask_loss: 0.0444 - val_loss: 0.3863 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.0948 - val_mrcnn_class_loss: 0.0604 - val_mrcnn_bbox_loss: 0.1019 - val_mrcnn_mask_loss: 0.1264\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 350s 4s/step - loss: 0.0690 - rpn_class_loss: 8.6956e-04 - rpn_bbox_loss: 0.0052 - mrcnn_class_loss: 0.0118 - mrcnn_bbox_loss: 0.0076 - mrcnn_mask_loss: 0.0436 - val_loss: 0.4207 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.1156 - val_mrcnn_class_loss: 0.0596 - val_mrcnn_bbox_loss: 0.1030 - val_mrcnn_mask_loss: 0.1397\n",
      "Epoch 11/30\n",
      " 27/100 [=======>......................] - ETA: 3:10 - loss: 0.0620 - rpn_class_loss: 9.0160e-04 - rpn_bbox_loss: 0.0029 - mrcnn_class_loss: 0.0105 - mrcnn_bbox_loss: 0.0067 - mrcnn_mask_loss: 0.0410100/100 [==============================] - 350s 3s/step - loss: 0.0640 - rpn_class_loss: 8.1363e-04 - rpn_bbox_loss: 0.0032 - mrcnn_class_loss: 0.0113 - mrcnn_bbox_loss: 0.0067 - mrcnn_mask_loss: 0.0419 - val_loss: 0.4181 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.1023 - val_mrcnn_class_loss: 0.0871 - val_mrcnn_bbox_loss: 0.0955 - val_mrcnn_mask_loss: 0.1306\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 349s 3s/step - loss: 0.0565 - rpn_class_loss: 7.0283e-04 - rpn_bbox_loss: 0.0021 - mrcnn_class_loss: 0.0106 - mrcnn_bbox_loss: 0.0052 - mrcnn_mask_loss: 0.0379 - val_loss: 0.3892 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.1117 - val_mrcnn_class_loss: 0.0529 - val_mrcnn_bbox_loss: 0.0860 - val_mrcnn_mask_loss: 0.1361\n",
      "Epoch 13/30\n",
      " 26/100 [======>.......................] - ETA: 3:13 - loss: 0.0537 - rpn_class_loss: 6.9387e-04 - rpn_bbox_loss: 0.0015 - mrcnn_class_loss: 0.0089 - mrcnn_bbox_loss: 0.0050 - mrcnn_mask_loss: 0.0376100/100 [==============================] - 350s 4s/step - loss: 0.0560 - rpn_class_loss: 7.0490e-04 - rpn_bbox_loss: 0.0014 - mrcnn_class_loss: 0.0111 - mrcnn_bbox_loss: 0.0048 - mrcnn_mask_loss: 0.0380 - val_loss: 0.4247 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1127 - val_mrcnn_class_loss: 0.0847 - val_mrcnn_bbox_loss: 0.0902 - val_mrcnn_mask_loss: 0.1343\n",
      "Epoch 14/30\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.0504 - rpn_class_loss: 6.7383e-04 - rpn_bbox_loss: 0.0012 - mrcnn_class_loss: 0.0097 - mrcnn_bbox_loss: 0.0040 - mrcnn_mask_loss: 0.0348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-44:\n",
      "Process Process-2:\n",
      "Process Process-45:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 680, in _data_generator_task\n",
      "    time.sleep(self.wait_time)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 678, in _data_generator_task\n",
      "    self.queue.put((True, generator_output))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<string>\", line 2, in put\n",
      "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/content/Mask_RCNN/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 612, in zoom\n",
      "    _nd_image.zoom_shift(filtered, zoom, None, output, order, mode, cval)\n",
      "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1217, in load_image_gt\n",
      "    mode=config.IMAGE_RESIZE_MODE)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/content/Mask_RCNN/mrcnn/utils.py\", line 453, in resize_image\n",
      "    order=1, mode=\"constant\", preserve_range=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\", line 135, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\", line 819, in warp\n",
      "    _clip_warp_output(image, warped, order, mode, cval, clip)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\", line 579, in _clip_warp_output\n",
      "    np.clip(output_image, min_val, max_val, out=output_image)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 1775, in clip\n",
      "    return _wrapfunc(a, 'clip', a_min, a_max, out=out)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 52, in _wrapfunc\n",
      "    return getattr(obj, method)(*args, **kwds)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/content/Mask_RCNN/samples/dataset_segmentation/segmentation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# Train or evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"splash\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         detect_and_color_splash(model, image_path=args.image,\n",
      "\u001b[0;32m/content/Mask_RCNN/samples/dataset_segmentation/segmentation.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 layers='heads')\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation)\u001b[0m\n\u001b[1;32m   2326\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         )\n\u001b[1;32m   2330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2248\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2250\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2251\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2252\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2397\u001b[0m                                      \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                                      str(generator_output))\n\u001b[0;32m-> 2399\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir('dataset_segmentation')\n",
    "%run ./segmentation.py train --dataset=./ --weights=coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nTO3w4IP1rU"
   },
   "source": [
    "# Save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8129,
     "status": "ok",
     "timestamp": 1524754312162,
     "user": {
      "displayName": "Rodolfo Bonnin",
      "photoUrl": "//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg",
      "userId": "106064727165962483576"
     },
     "user_tz": 180
    },
    "id": "kCMbbykhdTZ4",
    "outputId": "42a85de4-42e0-4689-d13f-d665ccbea115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation20180426T1226\r\n"
     ]
    }
   ],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "!ls ../../logs/\n",
    "\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "\n",
    "upload = drive.CreateFile()\n",
    "os.chdir('../../logs/segmentation20180426T1226/')\n",
    "upload.SetContentFile('mask_rcnn_segmentation_0013.h5')\n",
    "upload.Upload()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "5B_Object_segmentation_training.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
